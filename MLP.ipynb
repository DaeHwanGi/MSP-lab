{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from Chapter 4 of Machine Learning: An Algorithmic Perspective (2nd Edition)\n",
    "# by Stephen Marsland (http://stephenmonika.net)\n",
    " \n",
    "# You are free to use, change, or redistribute the code in any way you wish for\n",
    "# non-commercial purposes, but please maintain the name of the original author.\n",
    "# This code comes with no warranty of any kind.\n",
    " \n",
    "# Stephen Marsland, 2008, 2014\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class mlp:\n",
    "    \"\"\" A Multi-Layer Perceptron\"\"\"\n",
    "     \n",
    "    def __init__(self,inputs,targets,nhidden,beta=1,momentum=0.9,outtype='logistic'):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        self.nin = np.shape(inputs)[1] #입력 데이터의 종류\n",
    "        self.nout = np.shape(targets)[1] #목표값의 종류\n",
    "        self.ndata = np.shape(inputs)[0] #입력 데이터의 개수\n",
    "        self.nhidden = nhidden\n",
    " \n",
    "        self.beta = beta\n",
    "        self.outtype = outtype\n",
    "     \n",
    "        # Initialise network\n",
    "        #(nin+1, nhidden)크기의 배열을 가지며 -1과1 사이의 랜덤한 값을 입력값의 종류를 루트로 씌운 값으로 초기화\n",
    "        self.weights1 = (np.random.rand(self.nin+1,self.nhidden)-0.5)*2/np.sqrt(self.nin)\n",
    "        #(nhidden+1, nout)크기의 배열을 가지며 이번에는 은닉층의 개수를 루트로 씌움\n",
    "        self.weights2 = (np.random.rand(self.nhidden+1,self.nout)-0.5)*2/np.sqrt(self.nhidden)\n",
    " \n",
    "    def mlptrain(self,inputs,targets,eta,niterations):\n",
    "        \"\"\" Train the thing \"\"\"   \n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.ndata,1))),axis=1)\n",
    "        change = range(self.ndata)\n",
    "     \n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))#weight1 크기랑 같은 배열을 0으로 초기화\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))#weight2 크기랑 같은 배열을 0으로 초기화\n",
    "             \n",
    "        for n in range(niterations):\n",
    "     \n",
    "            self.outputs = self.predict(inputs) #결과는 전향의 결과\n",
    " \n",
    "            error = 0.5*np.sum((self.outputs-targets)**2) #에러제곱합 함수\n",
    "            if (np.mod(n,100)==0): #100의 배수마다 출력\n",
    "                print(\"Iteration: \",n, \" Error: \",error)   \n",
    " \n",
    "            # Different types of output neurons\n",
    "            if self.outtype == 'linear':\n",
    "              deltao = (self.outputs-targets)/self.ndata\n",
    "            elif self.outtype == 'logistic': #이진시그모이드 함수 베타는 기울기\n",
    "              deltao = self.beta*(self.outputs-targets)*self.outputs*(1.0-self.outputs)\n",
    "            elif self.outtype == 'softmax':\n",
    "                deltao = (self.outputs-targets)*(self.outputs*(-self.outputs)+self.outputs)/self.ndata\n",
    "            else:\n",
    "              print(\"error\")\n",
    "            #알파벳은 다르지만 델타제이가 시그모이드 기준으로 되어있다\n",
    "            deltah = self.hidden*self.beta*(1.0-self.hidden)*(np.dot(deltao,np.transpose(self.weights2)))\n",
    "             \n",
    "            updatew1 = eta*(np.dot(np.transpose(inputs),deltah[:,:-1]))\n",
    "            updatew2 = eta*(np.dot(np.transpose(self.hidden),deltao))\n",
    "            self.weights1 -= updatew1\n",
    "            self.weights2 -= updatew2\n",
    "                 \n",
    "            # Randomise order of inputs (not necessary for matrix-based calculation)\n",
    "            #np.random.shuffle(change)\n",
    "            #inputs = inputs[change,:]\n",
    "            #targets = targets[change,:]\n",
    "             \n",
    "    def predict(self,inputs): #전향\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "       \n",
    "        self.hidden = np.dot(inputs,self.weights1); #입력과 weight1의 곱\n",
    "        self.hidden = 1.0/(1.0+np.exp(-self.beta*self.hidden)) #시그모이드 활성화 함수를 적용\n",
    "        self.hidden = np.concatenate((self.hidden,-np.ones((np.shape(inputs)[0],1))),axis=1) #-1값을 갖는 바이어스 노드 추가\n",
    " \n",
    "        outputs = np.dot(self.hidden,self.weights2); #은닉층의 결과값과 weight2의 곱\n",
    " \n",
    "        # Different types of output neurons\n",
    "        if self.outtype == 'linear':\n",
    "          return outputs\n",
    "        elif self.outtype == 'logistic':\n",
    "            return 1.0/(1.0+np.exp(-self.beta*outputs))\n",
    "        elif self.outtype == 'softmax':\n",
    "            normalisers = np.sum(np.exp(outputs),axis=1)*np.ones((1,np.shape(outputs)[0]))\n",
    "            return np.transpose(np.transpose(np.exp(outputs))/normalisers)\n",
    "        else:\n",
    "            print(\"error\")\n",
    " \n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    " \n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "        outputs = self.predict(inputs)\n",
    "         \n",
    "        nclasses = np.shape(targets)[1]\n",
    " \n",
    "        if nclasses==1: #타겟의 종류가 1개일 때\n",
    "            nclasses = 2\n",
    "            outputs = np.where(outputs>0.5,1,0) #이진시그모이드 함수니까 0.5를 기준으로한다.\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    " \n",
    "        cm = np.zeros((nclasses,nclasses))\n",
    "        for i in range(nclasses):\n",
    "            for j in range(nclasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    " \n",
    "        print(\"Confusion matrix is:\")\n",
    "        print(cm)\n",
    "        print(\"Percentage Correct: \",np.trace(cm)/np.sum(cm)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Error:  0.774284078745208\n",
      "Iteration:  100  Error:  0.13431129287921859\n",
      "Iteration:  200  Error:  0.0078103822638562566\n",
      "Iteration:  300  Error:  0.0035773692008702054\n",
      "Iteration:  400  Error:  0.002275394581030628\n",
      "Iteration:  500  Error:  0.0016528320432634693\n",
      "Iteration:  600  Error:  0.001290958106123662\n",
      "Iteration:  700  Error:  0.0010555553328741776\n",
      "Iteration:  800  Error:  0.000890724361355521\n",
      "Iteration:  900  Error:  0.000769145390718317\n",
      "Iteration:  1000  Error:  0.0006759260445709824\n",
      "Confusion matrix is:\n",
      "[[3. 0.]\n",
      " [0. 1.]]\n",
      "Percentage Correct:  100.0\n",
      "Iteration:  0  Error:  0.5043100681927668\n",
      "Iteration:  100  Error:  0.497606639865956\n",
      "Iteration:  200  Error:  0.40043488441607544\n",
      "Iteration:  300  Error:  0.05667889038194658\n",
      "Iteration:  400  Error:  0.009152281729217325\n",
      "Iteration:  500  Error:  0.0049996109353807735\n",
      "Iteration:  600  Error:  0.0034160421284127104\n",
      "Iteration:  700  Error:  0.0025847614699353993\n",
      "Iteration:  800  Error:  0.0020742822001642586\n",
      "Iteration:  900  Error:  0.001729683514349577\n",
      "Iteration:  1000  Error:  0.0014817797945792751\n",
      "Iteration:  1100  Error:  0.001295079367713053\n",
      "Iteration:  1200  Error:  0.0011495243168639264\n",
      "Iteration:  1300  Error:  0.00103293540052764\n",
      "Iteration:  1400  Error:  0.0009374954059372663\n",
      "Iteration:  1500  Error:  0.0008579599248316274\n",
      "Iteration:  1600  Error:  0.0007906811428270968\n",
      "Iteration:  1700  Error:  0.0007330442847450311\n",
      "Iteration:  1800  Error:  0.0006831267537656489\n",
      "Iteration:  1900  Error:  0.0006394837221855828\n",
      "Iteration:  2000  Error:  0.0006010086759120807\n",
      "Iteration:  2100  Error:  0.0005668400517120239\n",
      "Iteration:  2200  Error:  0.0005362971367948981\n",
      "Iteration:  2300  Error:  0.0005088350711232453\n",
      "Iteration:  2400  Error:  0.000484012630974904\n",
      "Iteration:  2500  Error:  0.00046146875353721703\n",
      "Iteration:  2600  Error:  0.0004409051578558036\n",
      "Iteration:  2700  Error:  0.00042207329343281735\n",
      "Iteration:  2800  Error:  0.0004047644104802879\n",
      "Iteration:  2900  Error:  0.00038880191495070654\n",
      "Iteration:  3000  Error:  0.0003740354182378877\n",
      "Iteration:  3100  Error:  0.00036033605930503056\n",
      "Iteration:  3200  Error:  0.0003475927930146103\n",
      "Iteration:  3300  Error:  0.00033570941980052427\n",
      "Iteration:  3400  Error:  0.00032460218966217557\n",
      "Iteration:  3500  Error:  0.00031419785509282153\n",
      "Iteration:  3600  Error:  0.00030443207787162114\n",
      "Iteration:  3700  Error:  0.0002952481169657408\n",
      "Iteration:  3800  Error:  0.000286595741383785\n",
      "Iteration:  3900  Error:  0.00027843032427858443\n",
      "Iteration:  4000  Error:  0.000270712084031446\n",
      "Iteration:  4100  Error:  0.0002634054452542486\n",
      "Iteration:  4200  Error:  0.0002564784981908576\n",
      "Iteration:  4300  Error:  0.0002499025392988405\n",
      "Iteration:  4400  Error:  0.0002436516791496225\n",
      "Iteration:  4500  Error:  0.00023770250642403675\n",
      "Iteration:  4600  Error:  0.00023203379886717045\n",
      "Iteration:  4700  Error:  0.00022662627372725027\n",
      "Iteration:  4800  Error:  0.00022146237153188072\n",
      "Iteration:  4900  Error:  0.00021652606812405065\n",
      "Iteration:  5000  Error:  0.00021180271074472352\n",
      "Confusion matrix is:\n",
      "[[2. 0.]\n",
      " [0. 2.]]\n",
      "Percentage Correct:  100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "anddata = np.array([[0,0,0],[0,1,0],[1,0,0],[1,1,1]])\n",
    "xordata = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    " \n",
    "p = mlp(anddata[:,0:2],anddata[:,2:3],2)\n",
    "p.mlptrain(anddata[:,0:2],anddata[:,2:3],0.25,1001)\n",
    "p.confmat(anddata[:,0:2],anddata[:,2:3])\n",
    "\n",
    "q = mlp(xordata[:,0:2],xordata[:,2:3],2,outtype='logistic')\n",
    "q.mlptrain(xordata[:,0:2],xordata[:,2:3],0.25,5001)\n",
    "q.confmat(xordata[:,0:2],xordata[:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
